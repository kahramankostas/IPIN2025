{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da2acc0-1e24-45d8-aae2-1bee370327e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import confusion_matrix, silhouette_score\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "import argparse\n",
    "import os\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d47ae53b-15aa-489b-ad7d-b807065bb1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./fast_greedy_communities.csv',\n",
       " './infomap_communities.csv',\n",
       " './label_propagation_communities.csv',\n",
       " './leiden_communities.csv',\n",
       " './louvain_communities.csv',\n",
       " './node2vec.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_the_way(path,file_format,con=\"\"):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))  \n",
    "            \n",
    "    return files_add\n",
    "path=\"./\"\n",
    "files_add=find_the_way(path,'.csv')\n",
    "files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ba695-903f-4f4a-966a-5223b1bda3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d5d4a-1050-4a2e-b22b-05dd51a96269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d5fdc8-075d-4438-9b74-2346badb5a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== fast_greedy_communities. CLUSTERING PERFORMANCE METRICS ===\n",
      "\n",
      "--- Raw Cluster Evaluation ---\n",
      "Adjusted Rand Index: -0.0020\n",
      "Normalized Mutual Information: 0.1382\n",
      "Homogeneity: 0.1565\n",
      "Completeness: 0.1237\n",
      "V-measure: 0.1382\n",
      "\n",
      "--- Cluster-to-Floor Mapped Evaluation ---\n",
      "Accuracy: 0.4448\n",
      "Precision: 0.7277\n",
      "Recall: 0.4448\n",
      "F1-Score: 0.3555\n",
      "Adjusted Rand Index: 0.0542\n",
      "Normalized Mutual Information: 0.1651\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import confusion_matrix, silhouette_score\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_ground_truth(json_file):\n",
    "    \"\"\"Loads ground truth labels from a JSON file.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        gt_data = json.load(f)\n",
    "    ap_to_floor = {int(k): v for k, v in gt_data.items()}\n",
    "    return ap_to_floor\n",
    "\n",
    "def load_clustering_result(csv_file):\n",
    "    \"\"\"Loads clustering results from a CSV file.\"\"\"\n",
    "    clusters = []\n",
    "    with open(csv_file, 'r') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        for row in csv_reader:\n",
    "            cluster = [int(item.strip()) for item in row if item.strip() and item.strip().isdigit()]\n",
    "            if cluster:\n",
    "                clusters.append(cluster)\n",
    "    ap_to_cluster = {}\n",
    "    for cluster_id, aps in enumerate(clusters):\n",
    "        for ap in aps:\n",
    "            ap_to_cluster[ap] = cluster_id\n",
    "    return ap_to_cluster, clusters\n",
    "\n",
    "def map_clusters_to_floors(ap_to_floor, ap_to_cluster):\n",
    "    \"\"\"Maps clusters to floors (majority floor in the cluster becomes its label).\"\"\"\n",
    "    cluster_floor_counts = defaultdict(lambda: defaultdict(int))\n",
    "    common_aps = set(ap_to_floor.keys()) & set(ap_to_cluster.keys())\n",
    "    for ap in common_aps:\n",
    "        floor = ap_to_floor[ap]\n",
    "        cluster = ap_to_cluster[ap]\n",
    "        cluster_floor_counts[cluster][floor] += 1\n",
    "    cluster_to_floor = {}\n",
    "    for cluster, floor_counts in cluster_floor_counts.items():\n",
    "        cluster_to_floor[cluster] = max(floor_counts.items(), key=lambda x: x[1])[0]\n",
    "    return cluster_to_floor\n",
    "\n",
    "def create_true_pred_arrays(ap_to_floor, ap_to_cluster, cluster_to_floor):\n",
    "    \"\"\"Creates arrays of true and predicted labels for evaluation.\"\"\"\n",
    "    common_aps = sorted(set(ap_to_floor.keys()) & set(ap_to_cluster.keys()))\n",
    "    y_true = np.array([ap_to_floor[ap] for ap in common_aps])\n",
    "    y_pred_raw = np.array([ap_to_cluster[ap] for ap in common_aps])\n",
    "    y_pred_mapped = np.array([cluster_to_floor[ap_to_cluster[ap]] for ap in common_aps])\n",
    "    return common_aps, y_true, y_pred_raw, y_pred_mapped\n",
    "\n",
    "def evaluate_clustering(y_true, y_pred, prefix=\"\"):\n",
    "    \"\"\"Evaluates clustering performance and returns metrics.\"\"\"\n",
    "    results = {}\n",
    "    results[f\"{prefix}ari\"] = adjusted_rand_score(y_true, y_pred)\n",
    "    results[f\"{prefix}nmi\"] = normalized_mutual_info_score(y_true, y_pred)\n",
    "    results[f\"{prefix}homogeneity\"] = homogeneity_score(y_true, y_pred)\n",
    "    results[f\"{prefix}completeness\"] = completeness_score(y_true, y_pred)\n",
    "    results[f\"{prefix}v_measure\"] = v_measure_score(y_true, y_pred)\n",
    "    if prefix == \"mapped_\":\n",
    "        results[f\"{prefix}accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "        results[f\"{prefix}precision\"] = precision\n",
    "        results[f\"{prefix}recall\"] = recall\n",
    "        results[f\"{prefix}f1\"] = f1\n",
    "    return results\n",
    "\n",
    "def generate_confusion_matrix(y_true, y_pred, output_file, title):\n",
    "    \"\"\"Generates and saves a confusion matrix plot.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()  # Jupyter Notebook'ta grafiği göstermek için eklendi\n",
    "    plt.close()\n",
    "\n",
    "def analyze_clusters(clusters, ap_to_floor, output_dir):\n",
    "    \"\"\"Analyzes each cluster and visualizes floor distribution.\"\"\"\n",
    "    results = []\n",
    "    for cluster_id, aps in enumerate(clusters):\n",
    "        floor_counts = defaultdict(int)\n",
    "        valid_aps = 0\n",
    "        for ap in aps:\n",
    "            if ap in ap_to_floor:\n",
    "                floor_counts[ap_to_floor[ap]] += 1\n",
    "                valid_aps += 1\n",
    "        if not valid_aps:\n",
    "            continue\n",
    "        percentages = {floor: (count / valid_aps) * 100 for floor, count in floor_counts.items()}\n",
    "        dominant_floor = max(percentages.items(), key=lambda x: x[1]) if percentages else (None, 0)\n",
    "        results.append({\n",
    "            'cluster_id': cluster_id,\n",
    "            'total_aps': len(aps),\n",
    "            'valid_aps': valid_aps,\n",
    "            'floor_counts': dict(floor_counts),\n",
    "            'floor_percentages': percentages,\n",
    "            'dominant_floor': dominant_floor[0],\n",
    "            'dominant_percentage': dominant_floor[1]\n",
    "        })\n",
    "        if valid_aps > 0:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            floors = list(floor_counts.keys())\n",
    "            counts = list(floor_counts.values())\n",
    "            bars = plt.bar(floors, counts)\n",
    "            plt.xlabel('Floor')\n",
    "            plt.ylabel('Number of APs')\n",
    "            plt.title(f'Cluster {cluster_id} Floor Distribution')\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                         f'{int(height)}', ha='center', va='bottom')\n",
    "            plt.savefig(os.path.join(output_dir, f'cluster_{cluster_id}_distribution.pdf'))\n",
    "            #plt.show()  # Jupyter Notebook'ta grafiği göstermek için eklendi\n",
    "            plt.close()\n",
    "    with open(os.path.join(output_dir, 'cluster_analysis.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    return results\n",
    "\n",
    "for file in files_add:\n",
    "    \n",
    "\n",
    "    # Değişkenleri burada ayarlayın\n",
    "    gt_file = 'GT.json'  # Ground truth dosyası\n",
    "    result_file = file # Kümeleme sonuçları dosyası\n",
    "    output_dir = f'./results/{file[2:-3]}/'  # Çıktıların kaydedileceği dizin\n",
    "    # Çıktı dizinini oluştur\n",
    "    #s.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "        \n",
    "    # Ana fonksiyonu çalıştır\n",
    "    ap_to_floor = load_ground_truth(gt_file)\n",
    "    ap_to_cluster, clusters = load_clustering_result(result_file)\n",
    "    cluster_to_floor = map_clusters_to_floors(ap_to_floor, ap_to_cluster)\n",
    "    common_aps, y_true, y_pred_raw, y_pred_mapped = create_true_pred_arrays(\n",
    "        ap_to_floor, ap_to_cluster, cluster_to_floor\n",
    "    )\n",
    "    raw_results = evaluate_clustering(y_true, y_pred_raw, prefix=\"raw_\")\n",
    "    mapped_results = evaluate_clustering(y_true, y_pred_mapped, prefix=\"mapped_\")\n",
    "    all_results = {**raw_results, **mapped_results}\n",
    "    \n",
    "    print(f\"\\n=== {file[2:-3]} CLUSTERING PERFORMANCE METRICS ===\")\n",
    "    print(\"\\n--- Raw Cluster Evaluation ---\")\n",
    "    print(f\"Adjusted Rand Index: {raw_results['raw_ari']:.4f}\")\n",
    "    print(f\"Normalized Mutual Information: {raw_results['raw_nmi']:.4f}\")\n",
    "    print(f\"Homogeneity: {raw_results['raw_homogeneity']:.4f}\")\n",
    "    print(f\"Completeness: {raw_results['raw_completeness']:.4f}\")\n",
    "    print(f\"V-measure: {raw_results['raw_v_measure']:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Cluster-to-Floor Mapped Evaluation ---\")\n",
    "    print(f\"Accuracy: {mapped_results['mapped_accuracy']:.4f}\")\n",
    "    print(f\"Precision: {mapped_results['mapped_precision']:.4f}\")\n",
    "    print(f\"Recall: {mapped_results['mapped_recall']:.4f}\")\n",
    "    print(f\"F1-Score: {mapped_results['mapped_f1']:.4f}\")\n",
    "    print(f\"Adjusted Rand Index: {mapped_results['mapped_ari']:.4f}\")\n",
    "    print(f\"Normalized Mutual Information: {mapped_results['mapped_nmi']:.4f}\")\n",
    "    \n",
    "    # Sonuçları JSON dosyasına kaydet\n",
    "    with open(os.path.join(output_dir, 'performance_metrics.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_results, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    # Confusion matrix grafikleri oluştur\n",
    "    generate_confusion_matrix(\n",
    "        y_true, y_pred_raw,\n",
    "        os.path.join(output_dir, 'confusion_matrix_raw.pdf'),\n",
    "        'Confusion Matrix for Raw Clusters'\n",
    "    )\n",
    "    generate_confusion_matrix(\n",
    "        y_true, y_pred_mapped,\n",
    "        os.path.join(output_dir, 'confusion_matrix_mapped.pdf'),\n",
    "        'Confusion Matrix for Mapped Clusters'\n",
    "    )\n",
    "    \n",
    "    # Küme analizi yap\n",
    "    cluster_analysis = analyze_clusters(clusters, ap_to_floor, output_dir)\n",
    "    purities = [item['dominant_percentage'] for item in cluster_analysis]\n",
    "    avg_purity = sum(purities) / len(purities) if purities else 0\n",
    "    \n",
    "    print(f\"\\n--- Cluster Purity Analysis ---\")\n",
    "    print(f\"Average Cluster Purity: {avg_purity:.2f}%\")\n",
    "    print(f\"Minimum Cluster Purity: {min(purities):.2f}%\")\n",
    "    print(f\"Maximum Cluster Purity: {max(purities):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nAll results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17762942-afe6-4e04-b479-eefd465c884a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8331149-f5d3-4b6e-b916-842d728d4bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
